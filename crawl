#!/usr/bin/perl -s
#
# Perl script to crawl specified websites and return matches found
#
# By Andy Holyer 05/10/12
#
# usage: crawl "String" <site ...>
#

use warnings;
use WWW::Mechanize;
#use Data::Dumper;

# Variables we can tweak to change behaviour
my $DEBUG = 1;
my $DISPLAY_MISSES = 0;
my $CRAWL_MISSES = 1;
my $MAXDEPTH = 6;

my $string = shift(@ARGV);
my @URLS;
my %visited = ();
my $mech = WWW::Mechanize->new(
    autocheck => 0
    );

$mech->agent_alias('Mac Safari');

my %IGNORE_SCHEME = ( 
    'mailto' => 1,
    'ftp'    => 1,
    'javascript' => 1,
);    

# Populate the initial URL list
foreach my $url (@ARGV) {
    # Put on an http:// if it doesn't already exist....
    unless ($url =~ /^http/) {
	$url = "http://" . $url;
    }
    push @URLS, { url =>$url, 
		  path => []
    };
}

while (my $loc = shift(@URLS)) {
    crawl($string, $loc->{url}, $loc->{path});
       }

sub crawl {
    my ($string, $url, $path) = @_;

    # Are we at the max depth yet?
    if ($#{$path} >= $MAXDEPTH) {
	print STDERR "*** At Maximum depth: $url\n" if $DEBUG;
	return;
    }

    # Check we don't have a loop
    foreach my $u (@{$path}) {
	if ($u eq $url) {
	    print STDERR "*** Link loop at $url\n" if $DEBUG;
	return;
	}
    }

    $mech->get($url);
    unless ($mech->success()) {
	print STDERR "*** Get operation failed on $url\n" if $DEBUG;
	return;
    }

    # See if we match the query string
    my $content = $mech->content();
    my $matches = 0;
    $matches++  while ($content =~ /$string/ogi);

    if ( $DISPLAY_MISSES || ($matches > 0)) {
	# Output should be easy to paste into graphviz
	print '"';
	print join '" -> "', (@{$path}, $url);
	print '"' . "\n";
    }

    if ( $CRAWL_MISSES || ($matches >0)) {
	# Add all the links to the URL list

	foreach my $link ($mech->links()) {
	
	    # Not all types of URLS can be followed
	    next if $IGNORE_SCHEME{$link->url_abs()->scheme};
	    push @URLS, {
		url  => $link->url_abs()->as_string, 
		path => [ @{$path}, $url]
	    };
	}
    }
}
