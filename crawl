#!/usr/bin/perl -s
#
# Perl script to crawl specified websites and return matches found
#
# By Andy Holyer 05/10/12
#
# usage: crawl "String" <site ...>
#

use warnings;
use WWW::Mechanize;
#use Data::Dumper;

# Variables we can tweak to change behaviour
my $DEBUG = 1;
my $DISPLAY_MISSES = 0;
my $CRAWL_MISSES = 1;
my $MAXDEPTH = 10;

my $string = shift(@ARGV);
my @URLS;
my %visited = ();
my $mech = WWW::Mechanize->new(
    autocheck => 0
    );

$mech->agent_alias('Mac Safari');

my %IGNORE_SCHEME = ( 
    'mailto' => 1,
    'ftp'    => 1,
    'javascript' => 1,
);    

# Populate the initial URL list
foreach my $url (@ARGV) {
    # Put on an http:// if it doesn't already exist....
    unless ($url =~ /^http/) {
	$url = "http://" . $url;
    }
    push @URLS, { url =>$url, 
		  depth => 0
    };
}

while (my $loc = shift(@URLS)) {
    crawl($string, $loc->{url}, $loc->{depth});
       }

sub crawl {
    my ($string, $url, $depth) = @_;

    # Are we at the max depth yet?
    if ($depth >= $MAXDEPTH) {
	print STDERR "*** At Maximum depth: $url\n" if $DEBUG;
	return;
    }

    # Check it's not on the kill list
    if ($visited{$url}) {
	print STDERR "*** Already visited $url\n" if $DEBUG;
	return;
    } else {
	$visited{$url} = 1;
    }

    $mech->get($url);
    unless ($mech->success()) {
	print STDERR "*** Get operation failed on $url\n" if $DEBUG;
	return;
    }

    # See if we match the query string
    my $content = $mech->content();
    my $matches = 0;
    $matches++  while ($content =~ /$string/ogi);

    if ( $DISPLAY_MISSES || ($matches > 0)) {
	print "$url, \"$string\", $matches, $depth\n";
    }

    if ( $CRAWL_MISSES || ($matches >0)) {
	# Add all the links to the URL list

	foreach my $link ($mech->links()) {
	
	    # Not all types of URLS can be followed
	    next if $IGNORE_SCHEME{$link->url_abs()->scheme};
	    push @URLS, {
		url => $link->url_abs()->as_string, 
		depth =>$depth+1
	    };
	}
    }
}
